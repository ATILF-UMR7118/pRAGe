{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8518943,"sourceType":"datasetVersion","datasetId":4931502}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport time\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM\n)\n\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-05-29T05:14:11.830964Z","iopub.execute_input":"2024-05-29T05:14:11.831306Z","iopub.status.idle":"2024-05-29T05:14:19.141498Z","shell.execute_reply.started":"2024-05-29T05:14:11.831280Z","shell.execute_reply":"2024-05-29T05:14:19.140276Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/refomed/refomed_test.csv', sep='\\t')\nval_df = pd.read_csv('/kaggle/input/refomed/refomed_val.csv', sep='\\t')\n\nplm2key = {\"moussaKam/barthez-orangesum-abstract\": \"barthez-orangesum\",\n           #\"moussaKam/mbarthez-dialogue-summarization\":\"mbarthez-dialogue\"\n           #,\"moussaKam/mbarthez\":\"mbarthez\"\n           #,\"moussaKam/barthez\":\"barthez\"\n           #,\n           #\"amasi/barthez-orange-ft\": \"ftbarthez\"\n          }\n\ndevice = 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-05-29T06:24:42.660980Z","iopub.execute_input":"2024-05-29T06:24:42.661378Z","iopub.status.idle":"2024-05-29T06:24:42.685277Z","shell.execute_reply.started":"2024-05-29T06:24:42.661346Z","shell.execute_reply":"2024-05-29T06:24:42.684049Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for plm in list(plm2key.keys()):\n    \n    barthez_tokenizer = AutoTokenizer.from_pretrained(plm)\n    barthez_model = AutoModelForSeq2SeqLM.from_pretrained(plm).to(device)\n    barthez_model.eval()\n    for ip,prompt_template in enumerate(['','',\n                \"Expliquez-moi, en termes simples ou paraphrase ou définition :\",\n                \"Expliquez-moi le terme médical en mots simples, par une paraphrase ou une courte définition :\",\n              ]):\n        if ip <2:\n            continue\n        print(\"running\", plm,\"for p\",ip+1)\n\n        for T in [25]:\n\n            queries1 = []\n            for k in test_df.term:\n                queries1.append(prompt_template+f' {k}')\n\n            queries2 = []\n            for k in val_df.term:\n                queries2.append(prompt_template+f' {k}')\n\n            responses1 = []\n            tt1 = []\n            responses2 = []\n            tt2 = []\n            # ================================ test datframe =====================================\n            \n            for q in tqdm(queries1):\n                t1 = time.time()\n                input_ids = torch.tensor(\n                    [barthez_tokenizer.encode(q, add_special_tokens=True)]\n                )\n\n                predict = barthez_model.generate(input_ids.to(device), max_new_tokens=T)[0]\n                answer = barthez_tokenizer.decode(predict, skip_special_tokens=True)\n                t2 = time.time()\n                responses1.append(answer)\n                tt1.append(t2-t1)\n\n            pd.DataFrame({\"prompts\":queries1, \"zsa\": responses1, \"time_taken\":tt1}).to_csv(f'final_FT_{plm2key[plm]}_generation-p{ip}-test-{T}-redo.csv', sep='\\t', index=False)\n            # ================================ dev datframe =====================================\n\n            for q in tqdm(queries2):\n                t1 = time.time()\n                input_ids = torch.tensor(\n                    [barthez_tokenizer.encode(q, add_special_tokens=True)]\n                )\n\n                predict = barthez_model.generate(input_ids.to(device), max_new_tokens=T)[0]\n                answer = barthez_tokenizer.decode(predict, skip_special_tokens=True)\n                t2 = time.time()\n                responses2.append(answer)\n                tt2.append(t2-t1)\n                #break\n            pd.DataFrame({\"prompts\":queries2, \"zsa\": responses2, \"time_taken\":tt2}).to_csv(f'final_{plm2key[plm]}_generation-p{ip}-dev-{T}-redo.csv', sep='\\t', index=False)\n            ","metadata":{"execution":{"iopub.status.busy":"2024-05-29T06:24:45.096154Z","iopub.execute_input":"2024-05-29T06:24:45.097290Z","iopub.status.idle":"2024-05-29T07:02:51.450879Z","shell.execute_reply.started":"2024-05-29T06:24:45.097244Z","shell.execute_reply":"2024-05-29T07:02:51.448769Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7753864656c34d17b71ff09ffc560b18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/1.12M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb22ed1c4b3c4350995f90ebbd60bba7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.63M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78a1f90ba5ca4edfa9fd97f5b1bae245"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/557M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cda4a4cb9eb248499d14fe5b35408030"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:535: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"running moussaKam/barthez-orangesum-abstract for p 3\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1253/1253 [11:20<00:00,  1.84it/s]\n100%|██████████| 1063/1063 [09:36<00:00,  1.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"running moussaKam/barthez-orangesum-abstract for p 4\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1253/1253 [09:18<00:00,  2.24it/s]\n100%|██████████| 1063/1063 [07:45<00:00,  2.29it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}