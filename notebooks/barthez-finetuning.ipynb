{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8518943,"sourceType":"datasetVersion","datasetId":4931502}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers@v4.31-release","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:06:53.734994Z","iopub.execute_input":"2024-05-28T18:06:53.735387Z","iopub.status.idle":"2024-05-28T18:07:47.262436Z","shell.execute_reply.started":"2024-05-28T18:06:53.735358Z","shell.execute_reply":"2024-05-28T18:07:47.261270Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers@v4.31-release\n  Cloning https://github.com/huggingface/transformers (to revision v4.31-release) to /tmp/pip-req-build-bnjbv5ns\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-bnjbv5ns\n  Running command git checkout -b v4.31-release --track origin/v4.31-release\n  Switched to a new branch 'v4.31-release'\n  Branch 'v4.31-release' set up to track remote branch 'v4.31-release' from 'origin'.\n  Resolved https://github.com/huggingface/transformers to commit e51d7ac70ab8f3e69d3659226aa838308a668238\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (2.31.0)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.31.0) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.31.0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.31.0) (2024.2.2)\nDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.31.0-py3-none-any.whl size=7386692 sha256=2fde032380142c3c99a3508d0d7058038fead2b1bd749ff441519a76238014a1\n  Stored in directory: /tmp/pip-ephem-wheel-cache-zq3cx1f5/wheels/d7/b5/07/805e966c132d430bd04707e04f853f84106cf2c1565d6c56f3\nSuccessfully built transformers\nInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.39.3\n    Uninstalling transformers-4.39.3:\n      Successfully uninstalled transformers-4.39.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.14.3 requires transformers>=4.33.1, but you have transformers 4.31.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tokenizers-0.13.3 transformers-4.31.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import transformers\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom datasets import load_dataset, load_from_disk\nimport numpy as np\nimport nltk\nnltk.download('punkt')\n\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:07:47.264806Z","iopub.execute_input":"2024-05-28T18:07:47.265201Z","iopub.status.idle":"2024-05-28T18:08:07.750419Z","shell.execute_reply.started":"2024-05-28T18:07:47.265163Z","shell.execute_reply":"2024-05-28T18:08:07.749356Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-05-28 18:07:55.486469: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-28 18:07:55.486567: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-28 18:07:55.640296: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"max_input = 512\nmax_target = 256\nbatch_size = 3\nmodel_checkpoints = \"moussaKam/barthez-orangesum-abstract\"","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:09:53.036359Z","iopub.execute_input":"2024-05-28T18:09:53.036767Z","iopub.status.idle":"2024-05-28T18:09:53.041910Z","shell.execute_reply.started":"2024-05-28T18:09:53.036734Z","shell.execute_reply":"2024-05-28T18:09:53.040752Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/refomed/refomed_train.csv', sep='\\t')\nval_df = pd.read_csv('/kaggle/input/refomed/refomed_val.csv', sep='\\t')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:08:07.763339Z","iopub.execute_input":"2024-05-28T18:08:07.764109Z","iopub.status.idle":"2024-05-28T18:08:07.822982Z","shell.execute_reply.started":"2024-05-28T18:08:07.764075Z","shell.execute_reply":"2024-05-28T18:08:07.822218Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"prompts = ['','', \"Expliquez-moi, en termes simples ou paraphrase ou définition :\",\n\"Expliquez-moi le terme médical en mots simples, par une paraphrase ou une courte définition :\",\n]","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:08:07.824233Z","iopub.execute_input":"2024-05-28T18:08:07.824533Z","iopub.status.idle":"2024-05-28T18:08:07.829068Z","shell.execute_reply.started":"2024-05-28T18:08:07.824509Z","shell.execute_reply":"2024-05-28T18:08:07.828035Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:08:07.830353Z","iopub.execute_input":"2024-05-28T18:08:07.830684Z","iopub.status.idle":"2024-05-28T18:08:07.858426Z","shell.execute_reply.started":"2024-05-28T18:08:07.830641Z","shell.execute_reply":"2024-05-28T18:08:07.857548Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                              term  \\\n0                maladie de Chagas   \n1                       corticoïde   \n2                   polypathologie   \n3          symptôme non spécifique   \n4                crise généralisée   \n...                            ...   \n3976              thrombocytopénie   \n3977  manifestatios rhumatologique   \n3978                sinusite aiguë   \n3979           trouble ou handicap   \n3980                    médicament   \n\n                                             paraphrase  \n0             infection parasitaire à Trypanosoma cruzi  \n1     méthotrexate , mycophénolate mofétil , cycloph...  \n2                       plus d'une pathologie chronique  \n3     hypotension orthostatique , troubles digestifs...  \n4     tonicoclonique , atonique , voire à type d'abs...  \n...                                                 ...  \n3976  affection hématologique d'origine immune due à...  \n3977                                           arthrose  \n3978                     affections du nez et des sinus  \n3979                    tels que la paralysie cérébrale  \n3980    tel que la thérapie de substitution nicotinique  \n\n[3981 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>term</th>\n      <th>paraphrase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>maladie de Chagas</td>\n      <td>infection parasitaire à Trypanosoma cruzi</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>corticoïde</td>\n      <td>méthotrexate , mycophénolate mofétil , cycloph...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>polypathologie</td>\n      <td>plus d'une pathologie chronique</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>symptôme non spécifique</td>\n      <td>hypotension orthostatique , troubles digestifs...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>crise généralisée</td>\n      <td>tonicoclonique , atonique , voire à type d'abs...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3976</th>\n      <td>thrombocytopénie</td>\n      <td>affection hématologique d'origine immune due à...</td>\n    </tr>\n    <tr>\n      <th>3977</th>\n      <td>manifestatios rhumatologique</td>\n      <td>arthrose</td>\n    </tr>\n    <tr>\n      <th>3978</th>\n      <td>sinusite aiguë</td>\n      <td>affections du nez et des sinus</td>\n    </tr>\n    <tr>\n      <th>3979</th>\n      <td>trouble ou handicap</td>\n      <td>tels que la paralysie cérébrale</td>\n    </tr>\n    <tr>\n      <th>3980</th>\n      <td>médicament</td>\n      <td>tel que la thérapie de substitution nicotinique</td>\n    </tr>\n  </tbody>\n</table>\n<p>3981 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"all_train_prompts = []\nall_train_responses = []\nfor t,a in zip(train_df.term.values, train_df.paraphrase.values):\n    all_train_prompts.append(prompts[2] + t + ' [SEP]')\n    all_train_responses.append(prompts[2] + t + ' [SEP]' + a)\n    #break\nindex =100\nmodified_traindf = pd.DataFrame({'prompt':all_train_prompts[:],\n             'responses':all_train_responses[:]})\n\nall_val_prompts = []\nall_val_responses = []\nfor t,a in zip(val_df.term.values, val_df.paraphrase.values):\n    all_val_prompts.append(prompts[2] + t + ' [SEP]')\n    all_val_responses.append(prompts[2] + t + ' [SEP]' + a)\n    #break\n    \nmodified_valdf = pd.DataFrame({'prompt':all_val_prompts[:],\n             'responses':all_val_responses[:]})\n\nfrom datasets import Dataset\n\ntraindata = Dataset.from_pandas(modified_traindf)\nvaldata = Dataset.from_pandas(modified_valdf)\ntraindata, valdata","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:08:07.859410Z","iopub.execute_input":"2024-05-28T18:08:07.859688Z","iopub.status.idle":"2024-05-28T18:08:07.926805Z","shell.execute_reply.started":"2024-05-28T18:08:07.859665Z","shell.execute_reply":"2024-05-28T18:08:07.925893Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['prompt', 'responses'],\n     num_rows: 3981\n }),\n Dataset({\n     features: ['prompt', 'responses'],\n     num_rows: 1063\n }))"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess_data(data_to_process):\n  #get all the dialogues\n  inputs = [dialogue for dialogue in data_to_process['prompt']]\n  #tokenize the dialogues\n  model_inputs = tokenizer(inputs,  max_length=max_input, padding='max_length', truncation=True)\n  #tokenize the summaries\n  with tokenizer.as_target_tokenizer():\n    targets = tokenizer(data_to_process['responses'], max_length=max_target, padding='max_length', truncation=True)\n    \n  #set labels\n  model_inputs['labels'] = targets['input_ids']\n  #return the tokenized data\n  #input_ids, attention_mask and labels\n  return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:09:59.047965Z","iopub.execute_input":"2024-05-28T18:09:59.048340Z","iopub.status.idle":"2024-05-28T18:09:59.054535Z","shell.execute_reply.started":"2024-05-28T18:09:59.048312Z","shell.execute_reply":"2024-05-28T18:09:59.053424Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_checkpoints)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:10:00.018785Z","iopub.execute_input":"2024-05-28T18:10:00.019466Z","iopub.status.idle":"2024-05-28T18:10:07.384765Z","shell.execute_reply.started":"2024-05-28T18:10:00.019437Z","shell.execute_reply":"2024-05-28T18:10:07.383895Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"beffac7d852d488393e3df20e3fd7a6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/1.12M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"609f9a5d45e44c18a7dce0d60c89c044"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.63M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1826ef7a5f144804b8be0d512fb11bad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/557M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02ed3ccef82b4c0d9acb060a1daa2bb2"}},"metadata":{}}]},{"cell_type":"code","source":"tokenize_train_data = traindata.map(preprocess_data, batched = True)\ntokenize_val_data = valdata.map(preprocess_data, batched = True)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:10:07.386403Z","iopub.execute_input":"2024-05-28T18:10:07.386696Z","iopub.status.idle":"2024-05-28T18:10:09.754884Z","shell.execute_reply.started":"2024-05-28T18:10:07.386671Z","shell.execute_reply":"2024-05-28T18:10:09.753924Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3981 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cace089b52734149965607818879337b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3635: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1063 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d72cd97400c454bbf314a9dca51692e"}},"metadata":{}}]},{"cell_type":"code","source":"!pip install rouge.score nltk py7zr","metadata":{"execution":{"iopub.status.busy":"2024-05-28T08:23:04.014194Z","iopub.execute_input":"2024-05-28T08:23:04.014553Z","iopub.status.idle":"2024-05-28T08:23:29.960679Z","shell.execute_reply.started":"2024-05-28T08:23:04.014526Z","shell.execute_reply":"2024-05-28T08:23:29.959749Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting rouge.score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nCollecting py7zr\n  Downloading py7zr-0.21.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge.score) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge.score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge.score) (1.16.0)\nRequirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.7.0)\nCollecting pycryptodomex>=3.16.0 (from py7zr)\n  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\nCollecting pyzstd>=0.15.9 (from py7zr)\n  Downloading pyzstd-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\nCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\nCollecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting multivolumefile>=0.2.3 (from py7zr)\n  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting brotli>=1.1.0 (from py7zr)\n  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\nDownloading py7zr-0.21.0-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nDownloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyzstd-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.8/413.8 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge.score\n  Building wheel for rouge.score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge.score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=c5b05a94eee1a430f208802db90bfe06a24ec95e438629bbe1f9f6c0d4dc950d\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge.score\nInstalling collected packages: brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, rouge.score, py7zr\n  Attempting uninstall: brotli\n    Found existing installation: Brotli 1.0.9\n    Uninstalling Brotli-1.0.9:\n      Successfully uninstalled Brotli-1.0.9\nSuccessfully installed brotli-1.1.0 inflate64-1.0.0 multivolumefile-0.2.3 py7zr-0.21.0 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pyzstd-0.16.0 rouge.score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install evaluate rouge_score","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:10:09.755982Z","iopub.execute_input":"2024-05-28T18:10:09.756285Z","iopub.status.idle":"2024-05-28T18:10:25.810364Z","shell.execute_reply.started":"2024-05-28T18:10:09.756260Z","shell.execute_reply":"2024-05-28T18:10:25.809161Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m166.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=75ee24a8ef559f7a8b4780deb8ed8dac81f3d62a1fbd8e8d14451049a388d6b1\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score, evaluate\nSuccessfully installed evaluate-0.4.2 rouge_score-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nfrom evaluate import load\n\nrouge_scorer = evaluate.load('rouge')\n\ndef compute_rouge(pred):\n    predictions, labels = pred\n    #decode the predictions\\n\",\n    decode_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    #decode labels\\n\",\n    decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    #compute results\\n\",\n    res = rouge_scorer.compute(predictions=decode_predictions, references=decode_labels)\n    pred_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    res['gen_len'] = np.mean(pred_lens)\n    \n    return {k: round(v, 4) for k, v in res.items()}\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:10:25.812852Z","iopub.execute_input":"2024-05-28T18:10:25.813175Z","iopub.status.idle":"2024-05-28T18:10:28.248196Z","shell.execute_reply.started":"2024-05-28T18:10:25.813144Z","shell.execute_reply":"2024-05-28T18:10:28.247240Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a586b3c634894498b424918360d1d7bf"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric\n\nmetric = load_metric('rouge')\n\ndef compute_rouge(pred):\n    predictions, labels = pred\n    #decode the predictions\\n\",\n    decode_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    #decode labels\\n\",\n    decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    #compute results\\n\",\n    res = metric.compute(predictions=decode_predictions, references=decode_labels, use_stemmer=True)\n    #get\n    res = {key: value.mid.fmeasure * 100 for key, value in res.items()}\n    pred_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n    res['gen_len'] = np.mean(pred_lens)\n    \n    return {k: round(v, 4) for k, v in res.items()}","metadata":{"execution":{"iopub.status.busy":"2024-05-19T10:25:43.834885Z","iopub.execute_input":"2024-05-19T10:25:43.835368Z","iopub.status.idle":"2024-05-19T10:25:44.138962Z","shell.execute_reply.started":"2024-05-19T10:25:43.835319Z","shell.execute_reply":"2024-05-19T10:25:44.137981Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install huggingface_hub\n\n\n!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('<HFTOKEN>')\"","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:12:17.214482Z","iopub.execute_input":"2024-05-28T18:12:17.214847Z","iopub.status.idle":"2024-05-28T18:12:30.835655Z","shell.execute_reply.started":"2024-05-28T18:12:17.214817Z","shell.execute_reply":"2024-05-28T18:12:30.833875Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -rf /kaggle/working/ ","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:12:30.838102Z","iopub.execute_input":"2024-05-28T18:12:30.838464Z","iopub.status.idle":"2024-05-28T18:12:31.835377Z","shell.execute_reply.started":"2024-05-28T18:12:30.838427Z","shell.execute_reply":"2024-05-28T18:12:31.834273Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nrm: cannot remove '/kaggle/working/': Device or resource busy\n","output_type":"stream"}]},{"cell_type":"code","source":"collator = transformers.DataCollatorForSeq2Seq(tokenizer, model=model)\n\nargs = Seq2SeqTrainingArguments(\n    'barthez-orange-ft', #save directory\n    evaluation_strategy='epoch',\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size= 16,\n    gradient_accumulation_steps=8,\n    weight_decay=0.01,\n    save_total_limit=2,\n    num_train_epochs=20,\n    predict_with_generate=True,\n    eval_accumulation_steps=3,\n    fp16=True, #available only with CUDA\n    push_to_hub=True\n    )\n\ntrainer = Seq2SeqTrainer(\n    model, \n    args,\n    train_dataset=tokenize_train_data,\n    eval_dataset=tokenize_val_data,\n    data_collator=collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_rouge\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:12:37.453148Z","iopub.execute_input":"2024-05-28T18:12:37.453516Z","iopub.status.idle":"2024-05-28T18:15:20.756759Z","shell.execute_reply.started":"2024-05-28T18:12:37.453486Z","shell.execute_reply":"2024-05-28T18:15:20.755914Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\nFor more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n  warnings.warn(warning_message, FutureWarning)\nCloning https://huggingface.co/amasi/barthez-orange-ft into local empty directory.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Download file pytorch_model.bin:   0%|          | 8.00k/531M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63d0342c05f2443f93ae3a96306f010c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Download file runs/May28_13-27-04_0493eeec829d/events.out.tfevents.1716902836.0493eeec829d.34.0: 100%|########…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44589deaab6440cfbe91ba41a45e8902"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Download file runs/May28_14-37-29_0493eeec829d/events.out.tfevents.1716907063.0493eeec829d.34.3: 100%|########…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c2c9644074f4e0b91e0a39b4ef69e01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Download file runs/May28_14-05-53_0493eeec829d/events.out.tfevents.1716905168.0493eeec829d.34.1: 100%|########…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"873b3bb1db4641c5838c7d3cecc5f8fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Download file runs/May28_14-07-06_0493eeec829d/events.out.tfevents.1716905234.0493eeec829d.34.2: 100%|########…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34134a4482cd4ff6b5ad45c26f4bfe35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Download file training_args.bin: 100%|##########| 4.43k/4.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0380211e889a40d1bf505c20e79b3163"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file runs/May28_13-27-04_0493eeec829d/events.out.tfevents.1716902836.0493eeec829d.34.0:  15%|#4        |…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73b2131268cf4adaa6cfe2597ac8b57a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Download file sentencepiece.bpe.model:   1%|          | 8.74k/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a5befe6bbce44c793a292752d274109"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file runs/May28_14-37-29_0493eeec829d/events.out.tfevents.1716907063.0493eeec829d.34.3:  13%|#2        |…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6e504d905c84af3a84ef26d0020d100"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file runs/May28_14-07-06_0493eeec829d/events.out.tfevents.1716905234.0493eeec829d.34.2:  14%|#4        |…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a0f22c6798c43a0ada85f08e868f68f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file runs/May28_14-05-53_0493eeec829d/events.out.tfevents.1716905168.0493eeec829d.34.1:  15%|#4        |…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6980aa91794f4155ae784cdce0ffb556"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file training_args.bin:  23%|##2       | 1.00k/4.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"981bb7720c5d4099be285ab6bb7045e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file sentencepiece.bpe.model:   0%|          | 1.00k/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a56d7caf52d49cd9cc6d87aa79c9c7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Clean file pytorch_model.bin:   0%|          | 1.00k/531M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebb56d2ecdc7415b99a22d29802ec2e7"}},"metadata":{}}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:21:28.193864Z","iopub.execute_input":"2024-05-28T18:21:28.194720Z","iopub.status.idle":"2024-05-28T18:21:29.294573Z","shell.execute_reply.started":"2024-05-28T18:21:28.194689Z","shell.execute_reply":"2024-05-28T18:21:29.293553Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTue May 28 18:21:29 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   77C    P0              32W /  70W |    693MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   44C    P8              10W /  70W |      3MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-28T18:21:48.215361Z","iopub.execute_input":"2024-05-28T18:21:48.216306Z","iopub.status.idle":"2024-05-28T19:54:31.813154Z","shell.execute_reply.started":"2024-05-28T18:21:48.216265Z","shell.execute_reply":"2024-05-28T19:54:31.811837Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."},"metadata":{}},{"name":"stderr","text":"You're using a BarthezTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [620/620 1:32:14, Epoch 19/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>No log</td>\n      <td>4.666234</td>\n      <td>0.671900</td>\n      <td>0.653500</td>\n      <td>0.671800</td>\n      <td>0.672100</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.693852</td>\n      <td>0.671800</td>\n      <td>0.653500</td>\n      <td>0.671800</td>\n      <td>0.672100</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.293922</td>\n      <td>0.671800</td>\n      <td>0.653500</td>\n      <td>0.671800</td>\n      <td>0.672100</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.208902</td>\n      <td>0.671900</td>\n      <td>0.653500</td>\n      <td>0.671800</td>\n      <td>0.672100</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.188014</td>\n      <td>0.671900</td>\n      <td>0.653500</td>\n      <td>0.671800</td>\n      <td>0.672100</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.179520</td>\n      <td>0.671900</td>\n      <td>0.653500</td>\n      <td>0.671800</td>\n      <td>0.672100</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.175183</td>\n      <td>0.671900</td>\n      <td>0.653500</td>\n      <td>0.671800</td>\n      <td>0.672100</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>0.173190</td>\n      <td>0.671900</td>\n      <td>0.653500</td>\n      <td>0.671800</td>\n      <td>0.672100</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>0.171646</td>\n      <td>0.671900</td>\n      <td>0.653600</td>\n      <td>0.671900</td>\n      <td>0.672200</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>0.170701</td>\n      <td>0.671900</td>\n      <td>0.653600</td>\n      <td>0.671900</td>\n      <td>0.672200</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>No log</td>\n      <td>0.170366</td>\n      <td>0.671900</td>\n      <td>0.653600</td>\n      <td>0.671900</td>\n      <td>0.672200</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>No log</td>\n      <td>0.169647</td>\n      <td>0.671900</td>\n      <td>0.653600</td>\n      <td>0.671900</td>\n      <td>0.672200</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>No log</td>\n      <td>0.169761</td>\n      <td>0.671900</td>\n      <td>0.653600</td>\n      <td>0.671900</td>\n      <td>0.672200</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>No log</td>\n      <td>0.169496</td>\n      <td>0.671900</td>\n      <td>0.653600</td>\n      <td>0.671900</td>\n      <td>0.672200</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>No log</td>\n      <td>0.169276</td>\n      <td>0.671900</td>\n      <td>0.653600</td>\n      <td>0.671900</td>\n      <td>0.672200</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>No log</td>\n      <td>0.169089</td>\n      <td>0.671900</td>\n      <td>0.653600</td>\n      <td>0.671900</td>\n      <td>0.672200</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.974300</td>\n      <td>0.169080</td>\n      <td>0.671900</td>\n      <td>0.653600</td>\n      <td>0.671900</td>\n      <td>0.672200</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.974300</td>\n      <td>0.168958</td>\n      <td>0.671900</td>\n      <td>0.653600</td>\n      <td>0.671900</td>\n      <td>0.672200</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.974300</td>\n      <td>0.168878</td>\n      <td>0.671900</td>\n      <td>0.653600</td>\n      <td>0.671900</td>\n      <td>0.672200</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.974300</td>\n      <td>0.168904</td>\n      <td>0.671900</td>\n      <td>0.653600</td>\n      <td>0.671900</td>\n      <td>0.672200</td>\n      <td>20.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=620, training_loss=0.8175233994760821, metrics={'train_runtime': 5563.1578, 'train_samples_per_second': 14.312, 'train_steps_per_second': 0.111, 'total_flos': 2.417771357090611e+16, 'train_loss': 0.8175233994760821, 'epoch': 19.92})"},"metadata":{}}]},{"cell_type":"code","source":"from huggingface_hub import Repository\n\n# Define the repository where you want to push your model\nrepo_name = \"amasi/barthez-orange-ft\"\n!cd /kaggle/working/ && git init && git remote add origin && git pull origin main\n# Create a repository object\nrepo = Repository(local_dir=\"/kaggle/working/barthez-orange-ft/\", clone_from=repo_name)\n\n# Push the trained model to the repository\ntrainer.save_model(\"fine-tuned-model\")\nrepo.push_to_hub(commit_message=\"Initial model upload\")","metadata":{"execution":{"iopub.status.busy":"2024-05-28T20:26:24.957951Z","iopub.execute_input":"2024-05-28T20:26:24.958394Z","iopub.status.idle":"2024-05-28T20:27:17.000650Z","shell.execute_reply.started":"2024-05-28T20:26:24.958362Z","shell.execute_reply":"2024-05-28T20:27:16.999494Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nInitialized empty Git repository in /kaggle/working/.git/\nusage: git remote add [<options>] <name> <url>\n\n    -f, --fetch           fetch the remote branches\n    --tags                import all tags and associated objects when fetching\n                          or do not fetch any tag at all (--no-tags)\n    -t, --track <branch>  branch(es) to track\n    -m, --master <branch>\n                          master branch\n    --mirror[=(push|fetch)]\n                          set up remote as a mirror to push to or fetch from\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\nFor more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n  warnings.warn(warning_message, FutureWarning)\n/kaggle/working/barthez-orange-ft/ is already a clone of https://huggingface.co/amasi/barthez-orange-ft. Make sure you pull the latest changes with `repo.git_pull()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Upload file pytorch_model.bin:   0%|          | 1.00/531M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9faa9f256c24478792bfc6bc71021b71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload file runs/May28_18-12-37_04a002892927/events.out.tfevents.1716920508.04a002892927.34.0:   0%|          …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01a3accbb3ca4c47b76f2dab1b05d1e0"}},"metadata":{}},{"name":"stderr","text":"To https://huggingface.co/amasi/barthez-orange-ft\n   7d2deb0..8bfc824  main -> main\n\nTo https://huggingface.co/amasi/barthez-orange-ft\n   8bfc824..0142dfd  main -> main\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#tokenize the conversation\nmodel_inputs = tokenizer(sample,  max_length=512, padding='max_length', truncation=True)\n#make prediction\nraw_pred, _, _ = trainer.predict([model_inputs])\n#decode the output\nprint(tokenizer.decode(raw_pred[0]))","metadata":{"execution":{"iopub.status.busy":"2024-05-19T10:41:16.724665Z","iopub.execute_input":"2024-05-19T10:41:16.725042Z","iopub.status.idle":"2024-05-19T10:41:16.967404Z","shell.execute_reply.started":"2024-05-19T10:41:16.725010Z","shell.execute_reply":"2024-05-19T10:41:16.966454Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"</s><s> Expliquez-moi, en termes simples ou paraphrase ou définition :causes courantes</s>\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}