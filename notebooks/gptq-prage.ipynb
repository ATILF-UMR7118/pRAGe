{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8518943,"sourceType":"datasetVersion","datasetId":4931502}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install auto-gptq\n!pip install optimum\n!pip install bitsandbytes\n!pip install peft","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-29T12:31:00.293538Z","iopub.execute_input":"2024-05-29T12:31:00.294246Z","iopub.status.idle":"2024-05-29T12:32:02.824797Z","shell.execute_reply.started":"2024-05-29T12:31:00.294214Z","shell.execute_reply":"2024-05-29T12:32:02.823665Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting auto-gptq\n  Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nRequirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.29.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (2.18.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (1.26.4)\nCollecting rouge (from auto-gptq)\n  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\nCollecting gekko (from auto-gptq)\n  Downloading gekko-1.1.1-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (2.1.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (0.4.3)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (4.39.3)\nCollecting peft>=0.5.0 (from auto-gptq)\n  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from auto-gptq) (4.66.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (6.0.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2024.2.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (0.15.2)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->auto-gptq) (3.9.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge->auto-gptq) (1.16.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate>=0.26.0->auto-gptq) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->auto-gptq) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2023.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->auto-gptq) (1.3.0)\nDownloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gekko-1.1.1-py3-none-any.whl (13.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\nInstalling collected packages: rouge, gekko, peft, auto-gptq\nSuccessfully installed auto-gptq-0.7.1 gekko-1.1.1 peft-0.11.1 rouge-1.0.1\nCollecting optimum\n  Downloading optimum-1.19.2-py3-none-any.whl.metadata (19 kB)\nCollecting coloredlogs (from optimum)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.12)\nRequirement already satisfied: transformers<4.41.0,>=4.26.0 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.26.0->optimum) (4.39.3)\nRequirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.10/site-packages (from optimum) (2.1.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from optimum) (21.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optimum) (1.26.4)\nRequirement already satisfied: huggingface-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from optimum) (0.22.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum) (2.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2024.2.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->optimum) (3.1.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<4.41.0,>=4.26.0->transformers[sentencepiece]<4.41.0,>=4.26.0->optimum) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<4.41.0,>=4.26.0->transformers[sentencepiece]<4.41.0,>=4.26.0->optimum) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<4.41.0,>=4.26.0->transformers[sentencepiece]<4.41.0,>=4.26.0->optimum) (0.4.3)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.26.0->optimum) (0.2.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.41.0,>=4.26.0->optimum) (3.20.3)\nCollecting humanfriendly>=9.1 (from coloredlogs->optimum)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum) (3.9.1)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\nDownloading optimum-1.19.2-py3-none-any.whl (417 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.0/417.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, optimum\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 optimum-1.19.2\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.1\nRequirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.11.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.29.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install langchain_community","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:34:21.604046Z","iopub.execute_input":"2024-05-29T12:34:21.604366Z","iopub.status.idle":"2024-05-29T12:34:40.496915Z","shell.execute_reply.started":"2024-05-29T12:34:21.604341Z","shell.execute_reply":"2024-05-29T12:34:40.495820Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting langchain_community\n  Downloading langchain_community-0.2.1-py3-none-any.whl.metadata (8.9 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.1)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.4)\nCollecting langchain<0.3.0,>=0.2.0 (from langchain_community)\n  Downloading langchain-0.2.1-py3-none-any.whl.metadata (13 kB)\nCollecting langchain-core<0.3.0,>=0.2.0 (from langchain_community)\n  Downloading langchain_core-0.2.1-py3-none-any.whl.metadata (5.9 kB)\nCollecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n  Downloading langsmith-0.1.63-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.4)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.0->langchain_community)\n  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (2.5.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (1.33)\nCollecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain_community)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m904.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\nRequirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.9.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community) (2.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (2.14.6)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nDownloading langchain_community-0.2.1-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.2.1-py3-none-any.whl (973 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.2.1-py3-none-any.whl (308 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.5/308.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.1.63-py3-none-any.whl (122 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.8/122.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\nDownloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, orjson, langsmith, langchain-core, langchain-text-splitters, langchain, langchain_community\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.9.3 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.6 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.2.1 langchain-core-0.2.1 langchain-text-splitters-0.2.0 langchain_community-0.2.1 langsmith-0.1.63 orjson-3.10.3 packaging-23.2\n","output_type":"stream"}]},{"cell_type":"code","source":"                                                                                     \nimport re\nimport pandas as pd\nfrom tqdm import tqdm\nimport time\n\nfrom langchain_community.document_loaders import HuggingFaceDatasetLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_community.embeddings import HuggingFaceEmbeddings\nfrom langchain_community.vectorstores import FAISS\nfrom langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\nfrom langchain.chains import RetrievalQA\nfrom langchain_community.document_loaders.csv_loader import CSVLoader\n#from dotenv import load_dotenv\nfrom langchain.chains import LLMChain\nfrom langchain_community.llms import HuggingFaceHub\nfrom langchain.prompts import PromptTemplate\nimport torch\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM\n)\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, MistralForCausalLM\nfrom peft import prepare_model_for_kbit_training\nfrom peft import LoraConfig, get_peft_model #prepare_model_for_int8_training\nfrom datasets import load_dataset\nimport transformers\n\nfrom huggingface_hub import hf_hub_download\nimport torch\n\nimport argparse\nimport sys, csv\ncsv.field_size_limit(sys.maxsize)","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:34:53.715940Z","iopub.execute_input":"2024-05-29T12:34:53.716407Z","iopub.status.idle":"2024-05-29T12:35:13.100923Z","shell.execute_reply.started":"2024-05-29T12:34:53.716361Z","shell.execute_reply":"2024-05-29T12:35:13.099993Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-05-29 12:35:00.772155: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-29 12:35:00.772262: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-29 12:35:00.930060: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"131072"},"metadata":{}}]},{"cell_type":"markdown","source":"# Create database","metadata":{}},{"cell_type":"code","source":"!pip install sentence-transformers faiss-gpu","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:45:20.833089Z","iopub.execute_input":"2024-05-29T12:45:20.833445Z","iopub.status.idle":"2024-05-29T12:45:36.979988Z","shell.execute_reply.started":"2024-05-29T12:45:20.833415Z","shell.execute_reply":"2024-05-29T12:45:36.978983Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (3.0.0)\nCollecting faiss-gpu\n  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.22.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\nDownloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-gpu\nSuccessfully installed faiss-gpu-1.7.2\n","output_type":"stream"}]},{"cell_type":"code","source":"kbpath = '/kaggle/input/refomed/test_kb_petite.csv'\nENC = 'Lajavaness/sentence-camembert-large'\nenc = 'camem'\nquestion = '/kaggle/input/refomed/refomed_test.csv'","metadata":{"execution":{"iopub.status.busy":"2024-05-29T13:01:51.974494Z","iopub.execute_input":"2024-05-29T13:01:51.975197Z","iopub.status.idle":"2024-05-29T13:01:51.979497Z","shell.execute_reply.started":"2024-05-29T13:01:51.975167Z","shell.execute_reply":"2024-05-29T13:01:51.978451Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"loader = CSVLoader(\n        file_path=kbpath, source_column=\"title\",\n        csv_args={\n            \"delimiter\": \"\\t\",\n            #\"quotechar\": '\"',\n            \"fieldnames\": [\"index\", \"title\", \"text\", \"length\"],\n            },\n        )\npage_content_column = \"text\"\ndata = loader.load()\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n\n# 'data' holds the text you want to split, splitthe text into documents using the text splitter.\ndocs = text_splitter.split_documents(data)\n\nmodelPath = ENC\n#modelPath = \"sentence-transformers/all-MiniLM-L6-v2\"\n\n# Create a dictionary with model configuration options, specifying to use the CPU for computations\nmodel_kwargs = {'device':'cuda'}\n\n# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\nencode_kwargs = {'normalize_embeddings': False}\n\n# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\nembeddings = HuggingFaceEmbeddings(\n    model_name=modelPath,     # Provide the pre-trained model's path\n    model_kwargs=model_kwargs, # Pass the model configuration options\n    encode_kwargs=encode_kwargs # Pass the encoding options\n    )\n\ndb = FAISS.from_documents(docs, embeddings)\nretriever = db.as_retriever(search_kwargs={\"k\": 3})\nprint(\"database ready!\")","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:45:46.492469Z","iopub.execute_input":"2024-05-29T12:45:46.493272Z","iopub.status.idle":"2024-05-29T12:53:30.391421Z","shell.execute_reply.started":"2024-05-29T12:45:46.493237Z","shell.execute_reply":"2024-05-29T12:53:30.390480Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"database ready!\n","output_type":"stream"}]},{"cell_type":"code","source":"def remove_urls(text):\n    # Regex pattern to match http and https URLs\n    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n    # Substitute matched URLs with an empty string\n    cleaned_text = re.sub(url_pattern, '', text)\n    return cleaned_text\n\n\ndef prepare_context(docs):\n    cleaned_context, refs = [],[]\n    for d in docs:\n        raw_d = d.page_content.split('text:')[-1]\n        refs.append(str(d.metadata['row']))\n        cleaned_d = remove_urls(raw_d)\n        #print(raw_d ,\"|\", cleaned_d.split('length:')[0])\n        cleaned_context.append(cleaned_d.split('length:')[0])\n\n    return ' '.join(cleaned_context).strip().replace('\\n', ''), '-'.join(refs)\n\nprepare_context(docs)\nif 'test' in question:\n    split='test'\nelse:\n    split='val'\n\ntest_df = pd.read_csv(question, sep='\\t')","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:53:49.420249Z","iopub.execute_input":"2024-05-29T12:53:49.420636Z","iopub.status.idle":"2024-05-29T12:53:49.624107Z","shell.execute_reply.started":"2024-05-29T12:53:49.420592Z","shell.execute_reply":"2024-05-29T12:53:49.623256Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"base_prompt = \"Expliquez-moi le terme médical en mots simples, par une paraphrase ou une courte définition :\"\n\ncomplete_prompts = []\nsrc_docs = []\nfor term in tqdm(test_df.term):\n    retrieved_docs = retriever.get_relevant_documents(base_prompt+f' {term}')\n    cleaned_context, r = prepare_context(retrieved_docs)\n\n    complete_prmpt = f\"\"\"[INST] Vous êtes un expert en médecine. Utilisez les informations suivantes : [{cleaned_context}] {base_prompt}{term} [/INST]\"\"\"\n    complete_prompts.append(complete_prmpt)\n    src_docs.append(r)\n\nprint(\"Complete prompt ready!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T13:05:11.122535Z","iopub.execute_input":"2024-05-29T13:05:11.123151Z","iopub.status.idle":"2024-05-29T13:06:27.097401Z","shell.execute_reply.started":"2024-05-29T13:05:11.123107Z","shell.execute_reply":"2024-05-29T13:06:27.096418Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"100%|██████████| 1253/1253 [01:15<00:00, 16.49it/s]","output_type":"stream"},{"name":"stdout","text":"Complete prompt ready!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name = \"LoneStriker/BioMistral-7B-SLERP-GPTQ\"\nmodel = AutoModelForCausalLM.from_pretrained(model_name,\n                                             device_map=\"auto\", # automatically figures out how to best use CPU + GPU for loading model\n                                             trust_remote_code=False, # prevents running custom model files on your machine\n                                             revision=\"main\")\n\n\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T12:59:09.736508Z","iopub.execute_input":"2024-05-29T12:59:09.737156Z","iopub.status.idle":"2024-05-29T12:59:50.555582Z","shell.execute_reply.started":"2024-05-29T12:59:09.737112Z","shell.execute_reply":"2024-05-29T12:59:50.554589Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4208ca78a5d64b80b67e62df523ada90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/4.57G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3be163e08a74748ae31053e81c09677"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:4225: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de8f8d6d8a30496b8df6a2efab2be804"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3f8283e97914a259189f1a3f4093a96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18276857cda44e7da4d2472058377865"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"432039288af7417699abd10534e7c8cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"407177a9eac9438eb8aa6f2eabf37c83"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset\n\ntestdata = Dataset.from_pandas(pd.DataFrame(complete_prompts, columns=['prompt']))\n\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.truncation_side = \"right\"\ntokenizer.padding_side = \"left\" \ndef tokenize_function(examples):\n    # extract text\n    text = examples[\"prompt\"]\n    #tokenize and truncate text\n    #tokenizer.truncation_side = \"right\"\n    tokenized_inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        #padding=True,\n        padding='max_length',\n        max_length=512\n    )\n    return tokenized_inputs\n\ntokenized_testdata = testdata.map(tokenize_function, batched=True)\nprint(tokenized_testdata)\n#print(tokenized_testdata[4])\n\n# Define a collate function to pad inputs dynamically\ndef collate_fn(batch):\n    input_ids = torch.nn.utils.rnn.pad_sequence([torch.tensor(item['input_ids']) for item in batch], batch_first=True)\n    attention_mask = torch.nn.utils.rnn.pad_sequence([torch.tensor(item['attention_mask']) for item in batch], batch_first=True)\n    return {'input_ids': input_ids, 'attention_mask': attention_mask}\n\nbatch_size = 32  # Define your batch size\nfrom torch.utils.data import DataLoader\ndata_loader = DataLoader(tokenized_testdata, batch_size=batch_size, collate_fn=collate_fn)\nprint(\"dataloader ready....\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T13:07:38.435908Z","iopub.execute_input":"2024-05-29T13:07:38.436655Z","iopub.status.idle":"2024-05-29T13:07:39.140681Z","shell.execute_reply.started":"2024-05-29T13:07:38.436589Z","shell.execute_reply":"2024-05-29T13:07:39.139735Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1253 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98829a7b6a4641179fececd77b63818d"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 1253\n})\ndataloader ready....\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_testdata[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-29T13:07:41.442266Z","iopub.execute_input":"2024-05-29T13:07:41.443196Z","iopub.status.idle":"2024-05-29T13:07:41.468695Z","shell.execute_reply.started":"2024-05-29T13:07:41.443160Z","shell.execute_reply":"2024-05-29T13:07:41.467658Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'prompt': \"[INST] Vous êtes un expert en médecine. Utilisez les informations suivantes : [Anatomopathologie  L'anatomopathologie, anatomo-pathologie ou anatomie pathologique, informellement abrégée en « anat-patho » ou « anapath » dans le jargon des professionnels de la santé, est une spécialité médicale humaine et vétérinaire.  = Liens externes =Définition d'affectionAfetiv, Blog sur les relations affectives (fr) Portail de la psychologie  Ce sont des associations d'affections cancéreuses et de maladies diverses.] Expliquez-moi le terme médical en mots simples, par une paraphrase ou une courte définition :affection néoplasique [/INST]\",\n 'input_ids': [2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  2,\n  1,\n  733,\n  16289,\n  28793,\n  550,\n  607,\n  28705,\n  28876,\n  2097,\n  521,\n  7583,\n  481,\n  13138,\n  6669,\n  473,\n  28723,\n  16157,\n  864,\n  28764,\n  1514,\n  5227,\n  697,\n  15434,\n  6682,\n  714,\n  733,\n  2820,\n  16739,\n  23461,\n  7851,\n  28705,\n  393,\n  28742,\n  276,\n  16739,\n  23461,\n  7851,\n  28725,\n  396,\n  270,\n  14016,\n  28733,\n  1740,\n  7851,\n  3466,\n  396,\n  16739,\n  412,\n  2439,\n  1165,\n  1651,\n  28725,\n  5227,\n  301,\n  1044,\n  534,\n  28712,\n  4970,\n  2110,\n  481,\n  1509,\n  396,\n  270,\n  28733,\n  1740,\n  28709,\n  3488,\n  3466,\n  1509,\n  396,\n  377,\n  498,\n  3488,\n  2422,\n  462,\n  461,\n  926,\n  266,\n  634,\n  7585,\n  20408,\n  340,\n  543,\n  268,\n  440,\n  28797,\n  28725,\n  934,\n  2219,\n  27444,\n  4528,\n  3974,\n  15454,\n  745,\n  28706,\n  1997,\n  4262,\n  911,\n  363,\n  2959,\n  3160,\n  1380,\n  536,\n  28723,\n  28705,\n  327,\n  11469,\n  596,\n  7784,\n  274,\n  327,\n  28757,\n  28797,\n  3013,\n  685,\n  281,\n  28742,\n  2146,\n  10101,\n  24505,\n  299,\n  449,\n  28725,\n  21095,\n  1147,\n  1514,\n  3136,\n  5197,\n  1771,\n  325,\n  898,\n  28731,\n  4194,\n  614,\n  340,\n  543,\n  7140,\n  7851,\n  28705,\n  12494,\n  5497,\n  634,\n  25963,\n  281,\n  28742,\n  19528,\n  1308,\n  541,\n  22034,\n  267,\n  6912,\n  911,\n  340,\n  6125,\n  316,\n  497,\n  8125,\n  274,\n  20148,\n  13702,\n  1651,\n  28764,\n  28733,\n  28719,\n  3950,\n  462,\n  1850,\n  28706,\n  15454,\n  745,\n  481,\n  290,\n  1649,\n  1290,\n  2815,\n  28725,\n  940,\n  2219,\n  940,\n  377,\n  2176,\n  555,\n  3466,\n  2219,\n  1547,\n  424,\n  2306,\n  3013,\n  685,\n  714,\n  2146,\n  10101,\n  8688,\n  410,\n  11215,\n  1651,\n  733,\n  28748,\n  16289,\n  28793],\n 'attention_mask': [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1]}"},"metadata":{}}]},{"cell_type":"code","source":"model.eval()\ndevice = 'cuda'\nprint(\"Generation started......\")\nfor T in [50]:\n    queries2 = []\n    responses2 = []\n    times2 = []\n\n    for batch in tqdm(data_loader):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        #print(input_ids.shape)\n        t1 = time.time()\n        outputs = model.generate(input_ids=input_ids, \n                             attention_mask = attention_mask,\n                             max_new_tokens=T)\n        #print(outputs)\n        answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n        t2 = time.time()\n        responses2.extend(answer)\n        times2.extend([(t2-t1)/input_ids.shape[0]]*input_ids.shape[0])\n        #break\n\n    pd.DataFrame({\"prompt\":tokenized_testdata['prompt'], \n                      \"raga\": responses2, \n                      \"time_taken\":times2,\n                 \"src_docs\": src_docs}).to_csv(f'./final_gptq_{enc}_biom_p4-{split}-t{T}.csv', sep='\\t', index=False) \n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-29T13:37:00.207582Z","iopub.execute_input":"2024-05-29T13:37:00.207957Z","iopub.status.idle":"2024-05-29T14:25:32.749048Z","shell.execute_reply.started":"2024-05-29T13:37:00.207926Z","shell.execute_reply":"2024-05-29T14:25:32.748070Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Generation started......\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/40 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  2%|▎         | 1/40 [01:13<47:30, 73.09s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  5%|▌         | 2/40 [02:26<46:23, 73.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n  8%|▊         | 3/40 [03:39<45:09, 73.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 10%|█         | 4/40 [04:52<43:57, 73.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 12%|█▎        | 5/40 [06:06<42:46, 73.32s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 15%|█▌        | 6/40 [07:19<41:32, 73.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 18%|█▊        | 7/40 [08:32<40:18, 73.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 20%|██        | 8/40 [09:46<39:05, 73.29s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 22%|██▎       | 9/40 [10:59<37:52, 73.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 25%|██▌       | 10/40 [12:12<36:39, 73.31s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 28%|██▊       | 11/40 [13:26<35:26, 73.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 30%|███       | 12/40 [14:39<34:12, 73.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 32%|███▎      | 13/40 [15:52<32:59, 73.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 35%|███▌      | 14/40 [17:05<31:44, 73.27s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 38%|███▊      | 15/40 [18:19<30:31, 73.25s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 40%|████      | 16/40 [19:32<29:18, 73.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 42%|████▎     | 17/40 [20:45<28:03, 73.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 45%|████▌     | 18/40 [21:58<26:50, 73.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 48%|████▊     | 19/40 [23:11<25:37, 73.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 50%|█████     | 20/40 [24:25<24:24, 73.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 52%|█████▎    | 21/40 [25:38<23:11, 73.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 55%|█████▌    | 22/40 [26:51<21:57, 73.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 57%|█████▊    | 23/40 [28:04<20:44, 73.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 60%|██████    | 24/40 [29:17<19:30, 73.17s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 62%|██████▎   | 25/40 [30:31<18:17, 73.19s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 65%|██████▌   | 26/40 [31:44<17:05, 73.22s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 68%|██████▊   | 27/40 [32:57<15:51, 73.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 70%|███████   | 28/40 [34:10<14:38, 73.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 72%|███████▎  | 29/40 [35:24<13:25, 73.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 75%|███████▌  | 30/40 [36:37<12:12, 73.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 78%|███████▊  | 31/40 [37:50<10:58, 73.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 80%|████████  | 32/40 [39:03<09:46, 73.28s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 82%|████████▎ | 33/40 [40:17<08:32, 73.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 85%|████████▌ | 34/40 [41:30<07:19, 73.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 88%|████████▊ | 35/40 [42:43<06:06, 73.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 90%|█████████ | 36/40 [43:56<04:52, 73.24s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 92%|█████████▎| 37/40 [45:10<03:39, 73.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 95%|█████████▌| 38/40 [46:23<02:26, 73.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n 98%|█████████▊| 39/40 [47:36<01:13, 73.23s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n100%|██████████| 40/40 [48:32<00:00, 72.81s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"pd.DataFrame({\"prompt\":tokenized_testdata['prompt'], \n                      \"raga\": responses2, \n                      \"time_taken\":times2,\n                 \"src_docs\": src_docs}).to_csv(f'./final_gptq_{enc}_biom_p4-{split}-t{T}.csv', sep='\\t', index=False) ","metadata":{"execution":{"iopub.status.busy":"2024-05-29T13:36:42.037462Z","iopub.execute_input":"2024-05-29T13:36:42.037833Z","iopub.status.idle":"2024-05-29T13:36:42.148359Z","shell.execute_reply.started":"2024-05-29T13:36:42.037803Z","shell.execute_reply":"2024-05-29T13:36:42.147647Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}